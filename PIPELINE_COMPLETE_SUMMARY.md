# TAPIR + PopPUNK + Per-Clade SNP Analysis Pipeline - Complete Package

## Overview
Complete Nextflow DSL2 pipeline for phylogenetic analysis of bacterial genomes with Google Cloud Batch support, optimized for large datasets (400+ genomes) with ultra-conservative PopPUNK settings to prevent segmentation faults.

## Files Generated

### Core Pipeline Files
1. **`nextflow_tapir_poppunk_snp.nf`** - Main Nextflow DSL2 pipeline
   - Ultra-conservative PopPUNK settings for large datasets
   - Automatic parameter adjustment based on dataset size
   - Enhanced memory management and monitoring
   - Support for .fasta, .fa, .fas file extensions

2. **`nextflow.config`** - Comprehensive configuration file
   - Local execution profiles (ubuntu_docker, local_tmp, standard)
   - Google Cloud Batch profile with optimized resource allocation
   - Process-specific resource settings
   - Docker configuration fixes

3. **`poppunk_chunked_alternative.nf`** - Alternative chunked approach
   - For extremely large datasets that still cause segmentation faults
   - Processes genomes in smaller chunks (default: 200)
   - Merges results from all chunks

### Execution Scripts
4. **`run_pipeline.sh`** - Local execution script
   - Automated setup and execution for Ubuntu systems
   - Input validation and error checking
   - Progress monitoring integration

5. **`run_google_batch.sh`** - Google Cloud execution script
   - Automated Google Cloud setup and validation
   - API enablement and authentication checks
   - Cost-optimized execution with spot instances

6. **`setup_ubuntu_docker.sh`** - Docker environment setup
   - Fixes common Docker mount issues on Ubuntu
   - Creates necessary directories and permissions
   - Environment variable configuration

7. **`monitor_poppunk.sh`** - Real-time progress monitoring
   - Tracks PopPUNK progress for large datasets
   - Memory usage monitoring
   - Error detection and reporting

### Documentation
8. **`README.md`** - Comprehensive user guide
   - Usage instructions for all execution modes
   - Troubleshooting for common issues
   - Resource optimization guidelines
   - Examples for different scenarios

9. **`GOOGLE_CLOUD_SETUP.md`** - Google Cloud configuration guide
   - Prerequisites and permissions setup
   - Cost estimation and optimization
   - Monitoring and troubleshooting
   - Security considerations

10. **`TROUBLESHOOTING_GUIDE.md`** - Complete troubleshooting reference
    - PopPUNK segmentation fault solutions
    - Docker mount issue fixes
    - Google Cloud problem resolution
    - Performance optimization tips

## Key Features

### üîß **Ultra-Conservative PopPUNK Settings**
- **Automatic detection**: Datasets >450 samples use ultra-conservative parameters
- **Memory management**: 8 threads, 60GB RAM, 48-hour time limit
- **Parameter optimization**: Reduced sketch size and k-mer ranges
- **Progress monitoring**: Real-time memory and progress tracking

### ‚òÅÔ∏è **Google Cloud Batch Integration**
- **Project**: `erudite-pod-307018`
- **Scalable execution**: Automatic resource scaling
- **Cost optimization**: Spot instances for ~70% savings
- **Resource allocation**: Optimized machine types per process
- **Storage integration**: Google Cloud Storage for input/output

### üê≥ **Docker Optimization**
- **StaPH-B containers**: Latest versions of all tools
- **Ubuntu compatibility**: Fixed mount point issues
- **Multiple profiles**: Different configurations for various environments
- **Error handling**: Comprehensive Docker troubleshooting

### üìä **Large Dataset Support**
- **Tested for**: 400+ genomes (464 Burkholderia pseudomallei)
- **Chunked alternative**: For datasets that exceed memory limits
- **Adaptive parameters**: Automatic adjustment based on dataset size
- **Memory monitoring**: Real-time tracking and limits

## Execution Options

### 1. Local Ubuntu Execution (Recommended for Local)
```bash
./setup_ubuntu_docker.sh
./run_pipeline.sh
```

### 2. Google Cloud Batch (Recommended for Large Datasets)
```bash
./run_google_batch.sh
```

### 3. Manual Local Execution
```bash
nextflow run nextflow_tapir_poppunk_snp.nf -profile ubuntu_docker --input ./assemblies --resultsDir ./results
```

### 4. Manual Google Cloud Execution
```bash
nextflow run nextflow_tapir_poppunk_snp.nf -profile google_batch \
    --input gs://aphlhq-ngs-gh/nextflow_data/subset_100 \
    --resultsDir gs://aphlhq-ngs-gh/nextflow_data/subset_100_results \
    -w gs://aphlhq-ngs-gh/nextflow_work
```

### 5. Chunked Alternative (For Extreme Cases)
```bash
nextflow run poppunk_chunked_alternative.nf --input ./assemblies --resultsDir ./results --chunk_size 200
```

## Resource Requirements

### Local Execution
- **Minimum**: 32GB RAM, 8 CPU cores
- **Recommended**: 64GB RAM, 16+ CPU cores
- **Optimal**: 64GB+ RAM, 22 CPU cores (Intel Core Ultra 9 185H)

### Google Cloud Execution
- **PopPUNK**: n1-highmem-16 (16 vCPUs, 104GB RAM)
- **Panaroo**: n1-standard-8 (8 vCPUs, 30GB RAM)
- **Gubbins**: n1-standard-4 (4 vCPUs, 15GB RAM)
- **IQ-TREE**: n1-standard-4 (4 vCPUs, 15GB RAM)

## Performance Expectations

### Local Execution (464 genomes)
- **PopPUNK**: 24-48 hours (ultra-conservative settings)
- **Per-cluster analysis**: 2-8 hours per cluster (parallel)
- **Total runtime**: 1-3 days depending on cluster count

### Google Cloud Execution (100 genomes)
- **PopPUNK**: 2-4 hours
- **Total pipeline**: 4-8 hours
- **Estimated cost**: $20-40 (with spot instances)

### Google Cloud Execution (400+ genomes)
- **PopPUNK**: 8-16 hours
- **Total pipeline**: 12-24 hours
- **Estimated cost**: $80-150 (with spot instances)

## Validation Status
- ‚úÖ **Pipeline syntax**: Validated with Nextflow 24.10.5
- ‚úÖ **Help messages**: All pipelines display correctly
- ‚úÖ **Docker containers**: Latest StaPH-B versions specified
- ‚úÖ **Google Cloud config**: Properly configured for project
- ‚úÖ **Error handling**: Comprehensive troubleshooting included

## Container Versions (Latest StaPH-B)
- **PopPUNK**: `staphb/poppunk:2.7.5`
- **Panaroo**: `staphb/panaroo:1.5.2`
- **Gubbins**: `staphb/gubbins:3.3.5`
- **IQ-TREE2**: `staphb/iqtree2:2.4.0`

## Problem Solutions Implemented

### ‚úÖ PopPUNK Segmentation Faults
- Ultra-conservative resource allocation
- Adaptive parameter selection
- Memory monitoring and limits
- Chunked alternative approach

### ‚úÖ Docker Mount Issues
- Ubuntu-specific profiles
- Setup scripts for environment preparation
- Multiple fallback configurations

### ‚úÖ Large Dataset Handling
- Automatic detection of dataset size
- Conservative parameter adjustment
- Memory management optimization
- Progress monitoring tools

### ‚úÖ Google Cloud Integration
- Complete setup automation
- Cost optimization with spot instances
- Proper resource allocation per process
- Comprehensive monitoring and troubleshooting

## Quick Start Guide

### For Local Execution:
1. Ensure Docker is running
2. Run `./setup_ubuntu_docker.sh`
3. Place FASTA files in `./assemblies/`
4. Run `./run_pipeline.sh`
5. Monitor with `./monitor_poppunk.sh`

### For Google Cloud Execution:
1. Authenticate with Google Cloud
2. Upload FASTA files to input bucket
3. Run `./run_google_batch.sh`
4. Monitor through Google Cloud Console

The pipeline is production-ready and optimized for both local high-performance systems and scalable cloud execution, with comprehensive error handling and troubleshooting support.